# ASM-Hawk Hybrid Architecture
## TÃ­ch há»£p Ars0n Framework v2 Tools vá»›i Minimal Coupling

> **Philosophy**: Giá»¯ nguyÃªn tool containers tá»« ars0n, tá»± build orchestration layer phÃ¹ há»£p vá»›i Prisma.

---

## 1. Kiáº¿n TrÃºc Tá»•ng Thá»ƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ASM-HAWK v2                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [LAYER 1: Presentation]                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                           â”‚
â”‚  â”‚ Web (Next.js)â”‚ â†â”€â”€ Dashboard, Reports, Visualizations                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [LAYER 2: API Gateway]                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  NestJS API (:3000)                                                  â”‚   â”‚
â”‚  â”‚  - REST/GraphQL endpoints                                            â”‚   â”‚
â”‚  â”‚  - Authentication & Authorization                                    â”‚   â”‚
â”‚  â”‚  - Request validation                                                â”‚   â”‚
â”‚  â”‚  - Proxy to Recon Engine                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [LAYER 3: Orchestration]                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚              RECON ENGINE (Go) - Port 8443                              â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚
â”‚  â”‚  â”‚  Workflow Orchestrator                                          â”‚   â”‚â”‚
â”‚  â”‚  â”‚  - Company Discovery Workflow                                   â”‚   â”‚â”‚
â”‚  â”‚  â”‚  - Wildcard Subdomain Workflow                                  â”‚   â”‚â”‚
â”‚  â”‚  â”‚  - URL Attack Surface Workflow                                  â”‚   â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚
â”‚  â”‚  â”‚  Tool Executors (docker exec wrappers)                          â”‚   â”‚â”‚
â”‚  â”‚  â”‚  - SubfinderExecutor, NucleiExecutor, HttpxExecutor, etc.       â”‚   â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚
â”‚  â”‚  â”‚  Result Parsers & Normalizers                                   â”‚   â”‚â”‚
â”‚  â”‚  â”‚  - Parse JSON/text output â†’ Structured data                     â”‚   â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [LAYER 4: Background Jobs]                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ BullMQ Workers                   â”‚ â”‚ Scheduled Jobs (Cron)               â”‚â”‚
â”‚  â”‚ - Long-running scans             â”‚ â”‚ - Auto-discovery                   â”‚â”‚
â”‚  â”‚ - Result processing              â”‚ â”‚ - Periodic re-scans                â”‚â”‚
â”‚  â”‚ - Notification dispatch          â”‚ â”‚ - Data cleanup                     â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [LAYER 5: Data]                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ PostgreSQL      â”‚ â”‚ ClickHouse      â”‚ â”‚ Redis                           â”‚â”‚
â”‚  â”‚ + Prisma ORM    â”‚ â”‚ (Analytics/TSDB)â”‚ â”‚ (Cache/Queue)                   â”‚â”‚
â”‚  â”‚ - Scan results  â”‚ â”‚ - Historical    â”‚ â”‚ - Job queues                    â”‚â”‚
â”‚  â”‚ - Configs       â”‚ â”‚ - Metrics       â”‚ â”‚ - Session cache                 â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [LAYER 6: Tool Containers] (from ars0n-framework)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚subfinderâ”‚ â”‚  httpx â”‚ â”‚ nuclei â”‚ â”‚ katana â”‚ â”‚  ffuf  â”‚ â”‚  dnsx  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚gospiderâ”‚ â”‚wayback â”‚ â”‚shufflednsâ”‚ â”‚ cewl  â”‚ â”‚metabigorâ”‚ â”‚cloud_enumâ”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Sync Strategy vá»›i Ars0n Upstream

### 2.1. ThÆ° Má»¥c ÄÆ°á»£c Äá»“ng Bá»™ (SYNC)
CÃ¡c thÆ° má»¥c nÃ y copy trá»±c tiáº¿p tá»« ars0n khi cÃ³ update:

```
ars0n-framework-v2/
â””â”€â”€ docker/                    â†’ asm-hawk/docker/
    â”œâ”€â”€ subfinder/
    â”œâ”€â”€ nuclei/
    â”œâ”€â”€ httpx/
    â”œâ”€â”€ katana/
    â”œâ”€â”€ ffuf/
    â”œâ”€â”€ dnsx/
    â”œâ”€â”€ gospider/
    â”œâ”€â”€ waybackurls/
    â”œâ”€â”€ shuffledns/
    â”œâ”€â”€ cewl/
    â”œâ”€â”€ assetfinder/
    â”œâ”€â”€ metabigor/
    â”œâ”€â”€ sublist3r/
    â”œâ”€â”€ subdomainizer/
    â”œâ”€â”€ github-recon/
    â”œâ”€â”€ cloud_enum/
    â””â”€â”€ linkfinder/
```

### 2.2. ThÆ° Má»¥c Tham Kháº£o (REFERENCE)
Logic cÃ³ thá»ƒ khÃ¡c nhau, chá»‰ tham kháº£o updates:

```
ars0n-framework-v2/
â””â”€â”€ server/
    â”œâ”€â”€ utils/                  # Reference: Scan logic, parsing patterns
    â”œâ”€â”€ database.go             # Reference: Schema changes
    â””â”€â”€ types.go                # Reference: Type definitions
```

### 2.3. Script Tá»± Äá»™ng Sync

Táº¡o file `scripts/sync-ars0n-tools.sh`:

```bash
#!/bin/bash
# Sync tool containers from ars0n-framework-v2

ARS0N_PATH="/path/to/ars0n-framework-v2"
ASM_HAWK_PATH="/path/to/asm-hawk"

TOOLS=(
  "subfinder" "httpx" "nuclei" "katana" "ffuf" "dnsx"
  "gospider" "waybackurls" "shuffledns" "cewl" "assetfinder"
  "metabigor" "sublist3r" "subdomainizer" "github-recon"
  "cloud_enum" "linkfinder"
)

echo "ğŸ”„ Syncing ars0n tool containers..."

for tool in "${TOOLS[@]}"; do
  if [ -d "$ARS0N_PATH/docker/$tool" ]; then
    echo "  âœ“ Syncing $tool..."
    rsync -av --delete "$ARS0N_PATH/docker/$tool/" "$ASM_HAWK_PATH/docker/$tool/"
  fi
done

echo "âœ… Sync complete!"
echo "âš ï¸  Remember to rebuild containers: docker-compose build"
```

---

## 3. Recon Engine Architecture

### 3.1. Hiá»‡n Táº¡i (Port tá»« ars0n)
```
recon/
â”œâ”€â”€ main.go              # HTTP routes + handlers
â”œâ”€â”€ database.go          # Direct PostgreSQL (pgx)
â”œâ”€â”€ types.go             # Data structures
â””â”€â”€ utils/               # 38 utility files
    â”œâ”€â”€ amassUtils.go
    â”œâ”€â”€ subfinderUtils.go
    â””â”€â”€ ... (tool-specific)
```

### 3.2. Äá» Xuáº¥t Refactor (Clean Architecture)
```
recon/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ server/
â”‚       â””â”€â”€ main.go
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes.go
â”‚   â”‚   â”œâ”€â”€ middleware.go
â”‚   â”‚   â””â”€â”€ handlers/
â”‚   â”‚       â”œâ”€â”€ scan_handler.go
â”‚   â”‚       â””â”€â”€ config_handler.go
â”‚   â”œâ”€â”€ executor/                    # Tool execution layer
â”‚   â”‚   â”œâ”€â”€ interface.go             # ToolExecutor interface
â”‚   â”‚   â”œâ”€â”€ docker_executor.go       # docker exec wrapper
â”‚   â”‚   â””â”€â”€ tools/
â”‚   â”‚       â”œâ”€â”€ subfinder.go
â”‚   â”‚       â”œâ”€â”€ nuclei.go
â”‚   â”‚       â”œâ”€â”€ httpx.go
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ parser/                      # Output parsing
â”‚   â”‚   â”œâ”€â”€ interface.go
â”‚   â”‚   â””â”€â”€ parsers/
â”‚   â”‚       â”œâ”€â”€ json_parser.go
â”‚   â”‚       â”œâ”€â”€ line_parser.go
â”‚   â”‚       â””â”€â”€ tool_specific/
â”‚   â”œâ”€â”€ repository/                  # Data access (Prisma-compatible)
â”‚   â”‚   â”œâ”€â”€ interface.go
â”‚   â”‚   â””â”€â”€ postgres_repository.go
â”‚   â”œâ”€â”€ workflow/                    # Workflow orchestration
â”‚   â”‚   â”œâ”€â”€ company_workflow.go
â”‚   â”‚   â”œâ”€â”€ wildcard_workflow.go
â”‚   â”‚   â””â”€â”€ url_workflow.go
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ config.go
â”œâ”€â”€ pkg/
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ scan_models.go
â””â”€â”€ go.mod
```

---

## 4. Tool Executor Interface

### 4.1. Base Interface

```go
// internal/executor/interface.go
package executor

import "context"

type ScanRequest struct {
    ScopeTargetID string
    Target        string    // domain, ip, url depending on tool
    Options       map[string]interface{}
    Timeout       time.Duration
}

type ScanResult struct {
    ScanID        string
    Status        string    // "pending", "running", "completed", "failed"
    RawOutput     string
    ParsedResult  interface{}
    Error         error
    ExecutionTime time.Duration
    Command       string
}

type ToolExecutor interface {
    Name() string
    ContainerName() string
    Execute(ctx context.Context, req ScanRequest) (*ScanResult, error)
    ParseOutput(raw string) (interface{}, error)
    Validate(req ScanRequest) error
}
```

### 4.2. Docker Executor Base

```go
// internal/executor/docker_executor.go
package executor

import (
    "context"
    "fmt"
    "os/exec"
    "time"
)

type DockerExecutor struct {
    containerName string
}

func (d *DockerExecutor) DockerExec(ctx context.Context, args []string) (string, string, error) {
    cmdArgs := append([]string{"exec", d.containerName}, args...)
    cmd := exec.CommandContext(ctx, "docker", cmdArgs...)
    
    stdout, err := cmd.Output()
    if exitErr, ok := err.(*exec.ExitError); ok {
        return string(stdout), string(exitErr.Stderr), err
    }
    return string(stdout), "", err
}
```

### 4.3. Example: Subfinder Executor

```go
// internal/executor/tools/subfinder.go
package tools

import (
    "context"
    "strings"
    "time"
    
    "asm-hawk/recon/internal/executor"
)

type SubfinderExecutor struct {
    *executor.DockerExecutor
}

func NewSubfinderExecutor() *SubfinderExecutor {
    return &SubfinderExecutor{
        DockerExecutor: &executor.DockerExecutor{
            containerName: "asm-hawk-subfinder",
        },
    }
}

func (s *SubfinderExecutor) Name() string { return "subfinder" }
func (s *SubfinderExecutor) ContainerName() string { return "asm-hawk-subfinder" }

func (s *SubfinderExecutor) Execute(ctx context.Context, req executor.ScanRequest) (*executor.ScanResult, error) {
    start := time.Now()
    
    args := []string{"subfinder", "-d", req.Target, "-silent"}
    
    // Add rate limit if configured
    if rateLimit, ok := req.Options["rateLimit"].(int); ok {
        args = append(args, "-rate-limit", fmt.Sprintf("%d", rateLimit))
    }
    
    stdout, stderr, err := s.DockerExec(ctx, args)
    
    result := &executor.ScanResult{
        ScanID:        uuid.New().String(),
        Status:        "completed",
        RawOutput:     stdout,
        ExecutionTime: time.Since(start),
        Command:       strings.Join(args, " "),
    }
    
    if err != nil {
        result.Status = "failed"
        result.Error = err
    } else {
        parsed, _ := s.ParseOutput(stdout)
        result.ParsedResult = parsed
    }
    
    return result, nil
}

func (s *SubfinderExecutor) ParseOutput(raw string) (interface{}, error) {
    subdomains := []string{}
    for _, line := range strings.Split(raw, "\n") {
        if trimmed := strings.TrimSpace(line); trimmed != "" {
            subdomains = append(subdomains, trimmed)
        }
    }
    return subdomains, nil
}

func (s *SubfinderExecutor) Validate(req executor.ScanRequest) error {
    if req.Target == "" {
        return errors.New("target domain is required")
    }
    return nil
}
```

---

## 5. Prisma-Compatible Repository

```go
// internal/repository/postgres_repository.go
package repository

import (
    "context"
    "time"
    
    "github.com/jackc/pgx/v5/pgxpool"
)

type ScanRepository interface {
    // Generic scan operations
    CreateScan(ctx context.Context, tableName string, scan *ScanRecord) error
    UpdateScanStatus(ctx context.Context, tableName, scanID, status string) error
    UpdateScanResult(ctx context.Context, tableName, scanID string, result *ScanResult) error
    GetScan(ctx context.Context, tableName, scanID string) (*ScanRecord, error)
    ListScans(ctx context.Context, tableName, scopeTargetID string) ([]ScanRecord, error)
}

// ScanRecord matches Prisma schema structure
type ScanRecord struct {
    ID                string     `json:"id"`
    ScanID            string     `json:"scan_id"`
    ScopeTargetID     *string    `json:"scope_target_id"`
    Domain            string     `json:"domain,omitempty"`
    URL               string     `json:"url,omitempty"`
    CompanyName       string     `json:"company_name,omitempty"`
    Status            string     `json:"status"`
    Result            *string    `json:"result"`
    Error             *string    `json:"error"`
    Stdout            *string    `json:"stdout"`
    Stderr            *string    `json:"stderr"`
    Command           *string    `json:"command"`
    ExecutionTime     *string    `json:"execution_time"`
    CreatedAt         time.Time  `json:"created_at"`
    AutoScanSessionID *string    `json:"auto_scan_session_id"`
}

type PostgresRepository struct {
    pool *pgxpool.Pool
}

func (r *PostgresRepository) CreateScan(ctx context.Context, tableName string, scan *ScanRecord) error {
    // Dynamic query based on table name to match Prisma schema
    query := fmt.Sprintf(`
        INSERT INTO %s (scan_id, scope_target_id, domain, status, created_at)
        VALUES ($1, $2, $3, $4, NOW())
        RETURNING id
    `, tableName)
    
    return r.pool.QueryRow(ctx, query, 
        scan.ScanID, scan.ScopeTargetID, scan.Domain, scan.Status,
    ).Scan(&scan.ID)
}
```

---

## 6. Workflow Orchestration

```go
// internal/workflow/wildcard_workflow.go
package workflow

import (
    "context"
    "asm-hawk/recon/internal/executor/tools"
    "asm-hawk/recon/internal/repository"
)

type WildcardWorkflow struct {
    repo       repository.ScanRepository
    subfinder  *tools.SubfinderExecutor
    assetfinder *tools.AssetfinderExecutor
    httpx      *tools.HttpxExecutor
    // ... other tools
}

type WorkflowStep struct {
    Name      string
    Tool      executor.ToolExecutor
    DependsOn []string
    Enabled   bool
}

func (w *WildcardWorkflow) Execute(ctx context.Context, scopeTargetID, domain string) error {
    steps := []WorkflowStep{
        {Name: "subfinder", Tool: w.subfinder, Enabled: true},
        {Name: "assetfinder", Tool: w.assetfinder, DependsOn: []string{}, Enabled: true},
        {Name: "consolidate_round1", Tool: w.httpx, DependsOn: []string{"subfinder", "assetfinder"}, Enabled: true},
        // ... more steps
    }
    
    for _, step := range steps {
        if !step.Enabled {
            continue
        }
        
        // Wait for dependencies
        // Execute tool
        // Save results to Prisma via repository
    }
    
    return nil
}
```

---

## 7. Migration Path

### Phase 1: Foundation (Current)
- [x] Tool containers synced from ars0n
- [x] Prisma schema with all scan models
- [x] Basic recon engine (ported from ars0n)

### Phase 2: Refactor (Next Sprint)
- [ ] Abstract executor interface
- [ ] Separate parsing from execution
- [ ] Clean repository pattern

### Phase 3: Enhance (Future)
- [ ] Parallel workflow execution
- [ ] Better error handling & retry
- [ ] Progress streaming via WebSocket
- [ ] Result deduplication

### Phase 4: Scale (Production)
- [ ] Kubernetes deployment
- [ ] Tool container auto-scaling
- [ ] Distributed scanning across regions

---

## 8. Updating From Ars0n Upstream

When ars0n releases updates:

1. **Check Release Notes** - Identify what changed
2. **Sync Tool Containers** - Run `scripts/sync-ars0n-tools.sh`
3. **Review Logic Changes** - Compare `server/utils/*.go` 
4. **Update Schema if Needed** - Add new fields to `engine-schema.prisma`
5. **Test** - Run integration tests
6. **Rebuild Containers** - `docker-compose build`

---

## 9. Key Differences from Ars0n

| Aspect | Ars0n | ASM-Hawk |
|--------|-------|----------|
| ORM | Raw SQL (pgx) | Prisma |
| Language | Go only | Go + TypeScript |
| Frontend | React (bundled) | Next.js (separate) |
| Queue | None | BullMQ + Redis |
| Analytics | PostgreSQL | ClickHouse |
| Auth | None | JWT + RBAC |
| Multi-tenant | No | Yes |

---

## 10. Best Practices

1. **Never modify tool containers** - Sync-only from ars0n
2. **Keep parsing logic separate** - Easy to update when tool output changes
3. **Use interfaces everywhere** - Mock for testing
4. **Version your scans** - Track which tool version produced results
5. **Log everything** - Debugging distributed scans is hard
